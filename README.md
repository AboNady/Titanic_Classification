<h1 align="center">Titanic - Model for a Disaster!</h1>
<div>
  <p align="center">
    The Titanic classification problem is widely known for beginners, so I used my basic knowledge to answer the question "Will you survive?".
    <br/>
  </p>
</div>

<br/>
<div align="center">
  <a href="https://i.imgur.com/1qNaSpF.png">
    <img src="https://i.imgur.com/1qNaSpF.png" alt="Logo" width="860" height="444">
  </a>

<br/>
</div>

## Tech Stack

* **Python:** Version 3.10

* **Scikit-Learn**: Version 1.1.2

* **Pandas**: Version 1.4.3


## Details

* Feature engineering was the best thing I learned in this project; I dropped the nan columns because they were misleading for the classification algorithm. Then I replaced the nan values with the coulmn's mean.


* I splitted the dataset to 70% Train and 30% Test.

* I tried eight different classification algorithms and the results was as following:

LogisticRegression score is :  84.7
-----------
DecisionTreeClassifier Score is :  80.6%
-----------
KNeighborsClassifier Score is :  74.63%
-----------
GaussianNB Score is :  79.1%
-----------
SVC Score is :  67.54%
-----------
Perceptron Score is :  76.49%
-----------
SGDClassifier Score is :  81.34%
-----------
RandomForestClassifier Score is :  78.73%
-----------

<br/>
<br/>



## Contributing
Contributions are what makes the open source community such an amazing place to learn, inspire, and create. Any contributions you make are **greatly appreciated**.

If you have a suggestion that would make this better, please fork the repo and create a pull request. You can also simply open an issue with the tag "enhancement".
Do not forget to give the project a star! Thanks again!

<br/>

## License

Distributed under the MIT License. See `LICENSE.txt` for more information.





## References

*  The Kaggle [competition](https://www.kaggle.com/competitions/titanic)


## Contacts
* Via Email : Mahmoud.Nady@Ejust.edu.eg
* Via LinkidIn : https://www.linkedin.com/in/abonady/






